{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de877fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\IFFAH\n",
      "[nltk_data]     IZAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\IFFAH\n",
      "[nltk_data]     IZAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\IFFAH\n",
      "[nltk_data]     IZAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iffah Izazi Binti Abdul Halim(IS01080876)\n",
    "#Noor Farihin Binti Mohd Zuki(IS01081256)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6468eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('news_dataset.csv')\n",
    "\n",
    "# Use only the 'text' column\n",
    "texts = df['text'].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8ebc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphabet characters and convert to lower case\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text).lower()\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the texts\n",
    "processed_texts = texts.apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b89d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and a corpus\n",
    "dictionary = corpora.Dictionary(processed_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "# Define the number of topics\n",
    "num_topics = 4\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42, update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e619c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.6329014232038264\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_lda}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf56f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.078*\"q\" + 0.072*\"b\" + 0.022*\"p\" + 0.020*\"ax\" + 0.019*\"c\" + 0.018*\"n\" + 0.015*\"bh\" + 0.015*\"f\" + 0.014*\"h\" + 0.013*\"r\"\n",
      "Topic 1: 0.010*\"would\" + 0.009*\"one\" + 0.009*\"people\" + 0.006*\"u\" + 0.006*\"government\" + 0.006*\"know\" + 0.005*\"think\" + 0.005*\"right\" + 0.005*\"time\" + 0.005*\"say\"\n",
      "Topic 2: 0.027*\"key\" + 0.012*\"encryption\" + 0.012*\"chip\" + 0.009*\"db\" + 0.009*\"system\" + 0.008*\"use\" + 0.008*\"clipper\" + 0.007*\"x\" + 0.007*\"privacy\" + 0.007*\"bit\"\n",
      "Topic 3: 0.015*\"president\" + 0.009*\"stephanopoulos\" + 0.009*\"administration\" + 0.009*\"agency\" + 0.007*\"national\" + 0.007*\"turkish\" + 0.007*\"american\" + 0.006*\"security\" + 0.006*\"new\" + 0.006*\"tax\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(num_topics):\n",
    "    print(f'Topic {idx}: {topic}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The results from the LDA model provide us with four topics, each represented by a set of terms and their associated weights. \n",
    "\n",
    "#Topic 0: this topic is challenging to interpret meaningfully as it includes many single letters, for example (\"q\", \"b\", \"p\", \"ax\", \"c\", \"n\", \"bh\", \"f\", \"h\", \"r\") which are likely artifacts of pre-processing. \n",
    "\n",
    "#Topic 1: this topic more relates to cryptography and encryption technology. Words like key,\" \"chip,\" \"encryption,\" \"system,\" \"clipper,\" \"information,\" \"message,\" \"phone,\" and \"algorithm\". Suggest discussions around encryption methods and related technology. \n",
    "\n",
    "#Topic 2: this topic is quite general and seems to represent everyday conversations or common discussions. There are words like \"would,\" \"one,\" \"like,\" \"could,\" \"know,\" and \"get\" is commonly used in many context, it makes the topic less specific. \n",
    "\n",
    "#Topic 3: The topic more focus on politics and governance There are terms like  \"president\", \"turkish\", \"administration\", \"security\" \"new\" and \"tax\", \"agency\", . This suggest the  discussions around political issues, legal matters, and governance. \n",
    "\n",
    "#Coherence: Topics 1 and Topic 3 is quite coherent and are easy to interpret, suggest that they cover distinct areas. \n",
    "\n",
    "#Noise: Overall topic 0 seems to be noisy or may include data artifacts. if further with the text pre-processing, it could be beneficial. \n",
    "\n",
    "#General conversations: Topic 2 presents more generic discussions that could span into multiple subjects without focus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
